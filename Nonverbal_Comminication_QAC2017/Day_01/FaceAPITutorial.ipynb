{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1\n",
    "https://qiita.com/alfredplpl/items/5d1f9abf6ac93f6a9407\n",
    "\n",
    "Face API in Python Tutorial  \n",
    "https://docs.microsoft.com/ja-jp/azure/cognitive-services/face/tutorials/faceapiinpythontutorial\n",
    "\n",
    "Face API Reference\n",
    "https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236\n",
    "\n",
    "### Important\n",
    "The Video API Preview ended on October 30, 2017. To easily extract insights from videos, try the new Video Indexer API Preview. You also can use it to enhance content discovery experiences, such as search results, by detecting spoken words, faces, characters, and emotions. To learn more, see the Video Indexer Preview overview.\n",
    "\n",
    "## At First\n",
    "```bash\n",
    "# HTTP request\n",
    "pip install requests\n",
    "# opencv\n",
    "pip install opencv-python opencv-contrib-python \n",
    "# face api\n",
    "pip install cognitive_face\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face API Tutorial\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cognitive_face as CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load subscription_key\n",
    "AZURE_FACE_KEY (.gitignore) ã«è‡ªåˆ†ã®subscription_key ã‚’ä¿å­˜.  \n",
    "\n",
    "AZURE_FACE_KEY\n",
    "```text\n",
    "1è¡Œç›®: ã‚­ãƒ¼1\n",
    "2è¡Œç›®: ã‚­ãƒ¼2\n",
    "```\n",
    "ä½¿ç”¨ã™ã‚‹ã‚­ãƒ¼ã¯ã©ã¡ã‚‰ã§ã‚‚OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AZURE_FACE_KEY', 'r', encoding='utf-8')as f:\n",
    "    subscription_key_1 = f.readline().strip() # key1\n",
    "    subscription_key_2 = f.readline().strip() # key2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "CF.Key.set(subscription_key_1)\n",
    "\n",
    "# URLã«æ³¨æ„\n",
    "BASE_URL = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0'\n",
    "CF.BaseUrl.set(BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample image\n",
    "img_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect\n",
    "optionã§ï¼Œattributeã«'emotion'ã‚’è¶³ã™ã“ã¨ã§æ„Ÿæƒ…èªè­˜ã®çµæœãŒè¿”ã£ã¦ãã‚‹ï¼\n",
    "\n",
    "#### attribute ä¸€è¦§\n",
    "age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masashi/.anyenv/envs/pyenv/versions/3.6.5/lib/python3.6/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': '70058482-6fff-4533-9eb4-235b89b3182d', 'faceRectangle': {'top': 124, 'left': 459, 'width': 227, 'height': 227}, 'faceAttributes': {'emotion': {'anger': 0.103, 'contempt': 0.003, 'disgust': 0.038, 'fear': 0.003, 'happiness': 0.826, 'neutral': 0.006, 'sadness': 0.001, 'surprise': 0.02}}}]\n"
     ]
    }
   ],
   "source": [
    "# Detect\n",
    "faces = CF.face.detect(img_url,attributes='emotion') \n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ„Ÿæƒ…ã®ç¨®é¡\n",
    "FaceAPIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã‚‹æ„Ÿæƒ…ã®ç¨®é¡ã¯ï¼Œ  \n",
    "Plutickã®åŸºæœ¬æ„Ÿæƒ…8ç¨®+Neutralã§ã‚ã‚‹ãŸã‚ï¼Œãã‚Œã«å¯¾å¿œã—ãŸé¡”æ–‡å­—ã‚’ç”¨æ„ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    'anger': 'ğŸ˜ ', \n",
    "    'contempt': 'ğŸ˜', \n",
    "    'disgust': 'ğŸ˜¬', \n",
    "    'fear': 'ğŸ˜¨', \n",
    "    'happiness': 'ğŸ˜€', \n",
    "    'neutral': 'ğŸ˜', \n",
    "    'sadness': 'ğŸ˜¢', \n",
    "    'surprise': 'ğŸ˜¯'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyterä¸Šã§å‹•ç”»ã‚’ã†ã¾ãè¡¨ç¤ºã§ããªã„ãŸã‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¦å®Ÿè¡Œã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image\n",
    "PCã«ã¤ã„ã¦ã„ã‚‹Webã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã™ã‚‹ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
