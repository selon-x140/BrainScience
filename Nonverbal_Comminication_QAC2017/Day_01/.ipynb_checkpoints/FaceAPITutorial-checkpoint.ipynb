{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1\n",
    "https://qiita.com/alfredplpl/items/5d1f9abf6ac93f6a9407\n",
    "\n",
    "Face API in Python Tutorial  \n",
    "https://docs.microsoft.com/ja-jp/azure/cognitive-services/face/tutorials/faceapiinpythontutorial\n",
    "\n",
    "Face API Reference\n",
    "https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236\n",
    "\n",
    "### Important\n",
    "The Video API Preview ended on October 30, 2017. To easily extract insights from videos, try the new Video Indexer API Preview. You also can use it to enhance content discovery experiences, such as search results, by detecting spoken words, faces, characters, and emotions. To learn more, see the Video Indexer Preview overview.\n",
    "\n",
    "## At First\n",
    "```bash\n",
    "# HTTP request\n",
    "pip install requests\n",
    "# opencv\n",
    "pip install opencv-python opencv-contrib-python \n",
    "# face api\n",
    "pip install cognitive_face\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face API Tutorial\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cognitive_face as CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load subscription_key\n",
    "AZURE_FACE_KEY (.gitignore) に自分のsubscription_key を保存.  \n",
    "\n",
    "AZURE_FACE_KEY\n",
    "```text\n",
    "1行目: キー1\n",
    "2行目: キー2\n",
    "```\n",
    "使用するキーはどちらでもOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AZURE_FACE_KEY', 'r', encoding='utf-8')as f:\n",
    "    subscription_key_1 = f.readline().strip() # key1\n",
    "    subscription_key_2 = f.readline().strip() # key2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "CF.Key.set(subscription_key_1)\n",
    "\n",
    "# URLに注意\n",
    "BASE_URL = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0'\n",
    "CF.BaseUrl.set(BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample image\n",
    "img_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect\n",
    "optionで，attributeに'emotion'を足すことで感情認識の結果が返ってくる．\n",
    "\n",
    "#### attribute 一覧\n",
    "age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masashi/.anyenv/envs/pyenv/versions/3.6.5/lib/python3.6/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': '70058482-6fff-4533-9eb4-235b89b3182d', 'faceRectangle': {'top': 124, 'left': 459, 'width': 227, 'height': 227}, 'faceAttributes': {'emotion': {'anger': 0.103, 'contempt': 0.003, 'disgust': 0.038, 'fear': 0.003, 'happiness': 0.826, 'neutral': 0.006, 'sadness': 0.001, 'surprise': 0.02}}}]\n"
     ]
    }
   ],
   "source": [
    "# Detect\n",
    "faces = CF.face.detect(img_url,attributes='emotion') \n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 感情の種類\n",
    "FaceAPIのレスポンスに含まれる感情の種類は，  \n",
    "Plutickの基本感情8種+Neutralであるため，それに対応した顔文字を用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    'anger': '😠', \n",
    "    'contempt': '😞', \n",
    "    'disgust': '😬', \n",
    "    'fear': '😨', \n",
    "    'happiness': '😀', \n",
    "    'neutral': '😐', \n",
    "    'sadness': '😢', \n",
    "    'surprise': '😯'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter上で動画をうまく表示できないためスクリプトにて実行する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image\n",
    "PCについているWebカメラを使用する．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
